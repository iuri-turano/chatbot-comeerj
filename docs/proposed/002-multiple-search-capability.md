# Proposta 002: Capacidade de MÃºltiplas Buscas

**Status**: ğŸ”´ NÃƒO IMPLEMENTADO
**Prioridade**: ğŸ”¥ CRÃTICA
**EsforÃ§o Estimado**: MÃ©dio-Alto (6-8 horas)
**Impacto**: Alto - Melhora significativa na qualidade das respostas

---

## ğŸ“‹ Resumo

Implementar sistema de mÃºltiplas buscas automÃ¡ticas que identifica quando uma pergunta precisa de informaÃ§Ãµes adicionais e realiza buscas complementares para fornecer respostas mais completas e precisas.

## ğŸ¯ Objetivo Declarado (CLAUDE.md)

> "MÃºltiplas buscas automÃ¡ticas quando necessÃ¡rio para respostas mais completas"

**Comportamento Esperado:**
```
Pergunta Simples: "O que Ã© perispÃ­rito?"
â†’ 1 busca suficiente

Pergunta Complexa: "Qual a relaÃ§Ã£o entre perispÃ­rito, reencarnaÃ§Ã£o e evoluÃ§Ã£o espiritual?"
â†’ 3 buscas:
   1. "perispÃ­rito funÃ§Ã£o estrutura"
   2. "reencarnaÃ§Ã£o processo"
   3. "evoluÃ§Ã£o espiritual perispÃ­rito reencarnaÃ§Ã£o"
â†’ Correlaciona informaÃ§Ãµes de mÃºltiplas fontes
â†’ Resposta mais completa e fundamentada
```

## âŒ SituaÃ§Ã£o Atual

**ImplementaÃ§Ã£o**: Inexistente

**Comportamento Atual:**
- Apenas UMA busca por pergunta
- Usa query original sem expansÃ£o
- NÃ£o detecta necessidade de contexto adicional
- NÃ£o faz buscas complementares
- Pode perder informaÃ§Ãµes relevantes em perguntas complexas

**CÃ³digo Atual:**
```python
# backend/api_server.py (linha 435-440)
sources = prioritized_search(
    vectorstore,
    request.question,  # Query direta, sem expansÃ£o
    k=request.top_k,
    fetch_k=request.fetch_k
)
# UMA Ãºnica busca, resultado final
```

**Problemas:**
1. Respostas incompletas para perguntas complexas
2. Perda de contexto relevante em tÃ³picos inter-relacionados
3. NÃ£o aproveita mÃºltiplas perspectivas das obras
4. Viola promessa de "mÃºltiplas buscas automÃ¡ticas"
5. Qualidade inferior comparada a sistemas como Perplexity

**Arquivos Afetados:**
- `backend/api_server.py` (linhas 435-440, 552-557): Chamada Ãºnica de busca
- `backend/priority_retriever.py`: Apenas funÃ§Ã£o de busca simples

## âœ… SoluÃ§Ã£o Proposta

### Abordagem: Sistema Adaptativo Multi-Search

#### **EstratÃ©gia: 3 NÃ­veis de Complexidade**

```
NÃVEL 1 - Pergunta Simples (1 busca)
â”œâ”€ Pergunta direta sobre 1 conceito
â”œâ”€ Ex: "O que Ã© perispÃ­rito?"
â””â”€ EstratÃ©gia: 1 busca com query original

NÃVEL 2 - Pergunta MÃ©dia (2-3 buscas)
â”œâ”€ Pergunta sobre relaÃ§Ã£o entre 2-3 conceitos
â”œâ”€ Ex: "Qual a relaÃ§Ã£o entre perispÃ­rito e reencarnaÃ§Ã£o?"
â””â”€ EstratÃ©gia: 1 busca geral + 1-2 buscas especÃ­ficas

NÃVEL 3 - Pergunta Complexa (3-5 buscas)
â”œâ”€ Pergunta multi-facetada ou comparativa
â”œâ”€ Ex: "Compare as visÃµes sobre evoluÃ§Ã£o espiritual
â”‚      em O Livro dos EspÃ­ritos e O Evangelho"
â””â”€ EstratÃ©gia: 1 busca geral + mÃºltiplas especÃ­ficas + sÃ­ntese
```

### ImplementaÃ§Ã£o Detalhada

#### **Componente 1: Analisador de Complexidade**

```python
# backend/multi_search.py (NOVO ARQUIVO)

from typing import List, Dict, Tuple
import re
from langchain_community.llms import Ollama

class QueryAnalyzer:
    """Analisa complexidade de perguntas e extrai conceitos-chave"""

    # Palavras-chave que indicam comparaÃ§Ã£o/relaÃ§Ã£o
    COMPARATIVE_KEYWORDS = [
        "diferenÃ§a", "comparar", "relaÃ§Ã£o", "relaciona",
        "versus", "vs", "contraste", "semelhanÃ§a",
        "conexÃ£o", "liga", "influÃªncia"
    ]

    # Palavras-chave que indicam mÃºltiplos conceitos
    MULTI_CONCEPT_KEYWORDS = [
        "e", "ou", "alÃ©m", "tambÃ©m", "junto",
        "combinado", "integrado"
    ]

    # Conectores que dividem perguntas complexas
    QUESTION_SPLITTERS = [
        "e como", "e por que", "e quando", "e qual",
        "alÃ©m disso", "ademais", "tambÃ©m"
    ]

    def __init__(self):
        pass

    def analyze_complexity(self, question: str) -> Dict:
        """
        Analisa complexidade da pergunta

        Returns:
            {
                'complexity_level': int (1-3),
                'num_concepts': int,
                'concepts': List[str],
                'is_comparative': bool,
                'sub_questions': List[str],
                'recommended_searches': int
            }
        """

        # Normalizar pergunta
        q_lower = question.lower()

        # Detectar comparaÃ§Ã£o
        is_comparative = any(
            keyword in q_lower
            for keyword in self.COMPARATIVE_KEYWORDS
        )

        # Extrair conceitos espÃ­ritas principais
        concepts = self._extract_concepts(question)
        num_concepts = len(concepts)

        # Detectar sub-perguntas
        sub_questions = self._split_complex_question(question)

        # Determinar nÃ­vel de complexidade
        complexity_level = self._determine_complexity_level(
            num_concepts,
            is_comparative,
            len(sub_questions),
            question
        )

        # Recomendar nÃºmero de buscas
        recommended_searches = self._recommend_num_searches(
            complexity_level,
            num_concepts,
            is_comparative
        )

        return {
            'complexity_level': complexity_level,
            'num_concepts': num_concepts,
            'concepts': concepts,
            'is_comparative': is_comparative,
            'sub_questions': sub_questions,
            'recommended_searches': recommended_searches
        }

    def _extract_concepts(self, question: str) -> List[str]:
        """Extrai conceitos espÃ­ritas da pergunta"""

        # Lista de conceitos espÃ­ritas comuns
        SPIRITIST_CONCEPTS = [
            "perispÃ­rito", "reencarnaÃ§Ã£o", "mediunidade", "mÃ©dium",
            "espÃ­rito", "desencarnaÃ§Ã£o", "obsessÃ£o", "caridade",
            "evangelho", "prece", "fluido", "passe", "evoluÃ§Ã£o",
            "karma", "lei de causa e efeito", "livre arbÃ­trio",
            "destino", "plano espiritual", "erraticidade",
            "expiaÃ§Ã£o", "provaÃ§Ã£o", "missÃ£o", "intuiÃ§Ã£o"
        ]

        q_lower = question.lower()
        found_concepts = []

        for concept in SPIRITIST_CONCEPTS:
            if concept in q_lower:
                found_concepts.append(concept)

        # Se nÃ£o encontrou conceitos especÃ­ficos, tentar extrair substantivos
        if not found_concepts:
            # Extrair palavras principais (heurÃ­stica simples)
            words = re.findall(r'\b[a-zÃ¡Ã Ã¢Ã£Ã©Ã¨ÃªÃ­Ã¯Ã³Ã´ÃµÃ¶ÃºÃ§Ã±]{4,}\b', q_lower)
            # Pegar atÃ© 3 palavras mais longas como conceitos
            found_concepts = sorted(set(words), key=len, reverse=True)[:3]

        return found_concepts

    def _split_complex_question(self, question: str) -> List[str]:
        """Divide pergunta complexa em sub-perguntas"""

        sub_questions = []

        # Dividir por conectores
        for splitter in self.QUESTION_SPLITTERS:
            if splitter in question.lower():
                parts = re.split(
                    re.escape(splitter),
                    question,
                    flags=re.IGNORECASE
                )
                sub_questions.extend([p.strip() for p in parts if p.strip()])

        # Se nÃ£o dividiu, retornar pergunta original
        if not sub_questions:
            sub_questions = [question]

        return sub_questions

    def _determine_complexity_level(
        self,
        num_concepts: int,
        is_comparative: bool,
        num_sub_questions: int,
        question: str
    ) -> int:
        """
        Determina nÃ­vel de complexidade (1, 2 ou 3)

        CritÃ©rios:
        - NÃVEL 1: Pergunta simples, 1 conceito, direta
        - NÃVEL 2: 2-3 conceitos OU comparativa OU 2 sub-perguntas
        - NÃVEL 3: 4+ conceitos OU 3+ sub-perguntas OU muito complexa
        """

        # Complexidade baseada em mÃºltiplos fatores
        complexity_score = 0

        # Fator 1: NÃºmero de conceitos
        if num_concepts == 1:
            complexity_score += 1
        elif num_concepts <= 3:
            complexity_score += 2
        else:
            complexity_score += 3

        # Fator 2: ComparaÃ§Ã£o
        if is_comparative:
            complexity_score += 1

        # Fator 3: Sub-perguntas
        if num_sub_questions > 2:
            complexity_score += 1

        # Fator 4: Comprimento da pergunta (proxy de complexidade)
        if len(question) > 100:
            complexity_score += 1

        # Mapear score para nÃ­vel
        if complexity_score <= 2:
            return 1  # Simples
        elif complexity_score <= 4:
            return 2  # MÃ©dia
        else:
            return 3  # Complexa

    def _recommend_num_searches(
        self,
        complexity_level: int,
        num_concepts: int,
        is_comparative: bool
    ) -> int:
        """Recomenda nÃºmero de buscas baseado na complexidade"""

        if complexity_level == 1:
            return 1

        elif complexity_level == 2:
            if is_comparative:
                return 3  # 1 para cada lado + 1 geral
            else:
                return min(num_concepts + 1, 3)

        else:  # complexity_level == 3
            if is_comparative:
                return min(num_concepts * 2, 5)
            else:
                return min(num_concepts + 2, 5)


class MultiSearchEngine:
    """Engine para realizar mÃºltiplas buscas e combinar resultados"""

    def __init__(self, vectorstore, llm=None):
        self.vectorstore = vectorstore
        self.llm = llm
        self.analyzer = QueryAnalyzer()

    def multi_search(
        self,
        question: str,
        k: int = 3,
        fetch_k: int = 15,
        max_searches: int = 5
    ) -> Tuple[List, Dict]:
        """
        Realiza mÃºltiplas buscas e combina resultados

        Returns:
            (combined_sources, metadata)
            - combined_sources: Lista de documentos Ãºnicos
            - metadata: InformaÃ§Ãµes sobre as buscas realizadas
        """

        # Analisar complexidade
        analysis = self.analyzer.analyze_complexity(question)

        # Limitar nÃºmero de buscas
        num_searches = min(
            analysis['recommended_searches'],
            max_searches
        )

        print(f"ğŸ” AnÃ¡lise: NÃ­vel {analysis['complexity_level']}, "
              f"{analysis['num_concepts']} conceitos, "
              f"{num_searches} buscas recomendadas")

        # Gerar queries para cada busca
        search_queries = self._generate_search_queries(
            question,
            analysis,
            num_searches
        )

        print(f"ğŸ“ Queries geradas:")
        for i, query in enumerate(search_queries, 1):
            print(f"   {i}. {query}")

        # Realizar buscas
        all_sources = []
        search_results = []

        for i, query in enumerate(search_queries):
            print(f"ğŸ” Busca {i+1}/{len(search_queries)}: {query[:50]}...")

            from priority_retriever import prioritized_search

            sources = prioritized_search(
                self.vectorstore,
                query,
                k=k,
                fetch_k=fetch_k
            )

            search_results.append({
                'query': query,
                'num_results': len(sources),
                'sources': sources
            })

            all_sources.extend(sources)

        # Remover duplicatas e reranquear
        unique_sources = self._deduplicate_and_rerank(
            all_sources,
            question,
            k=k * num_searches  # Mais resultados para perguntas complexas
        )

        print(f"âœ… Total: {len(all_sources)} documentos, "
              f"{len(unique_sources)} Ãºnicos")

        metadata = {
            'complexity_analysis': analysis,
            'num_searches': num_searches,
            'search_queries': search_queries,
            'search_results': search_results,
            'total_documents': len(all_sources),
            'unique_documents': len(unique_sources)
        }

        return unique_sources, metadata

    def _generate_search_queries(
        self,
        question: str,
        analysis: Dict,
        num_searches: int
    ) -> List[str]:
        """Gera mÃºltiplas queries de busca"""

        queries = []

        # Query 1: Sempre incluir pergunta original
        queries.append(question)

        if num_searches == 1:
            return queries

        # Query 2+: Baseado em conceitos e complexidade
        concepts = analysis['concepts']

        if analysis['is_comparative'] and len(concepts) >= 2:
            # Buscas separadas para cada lado da comparaÃ§Ã£o
            for concept in concepts[:num_searches-1]:
                queries.append(f"{concept} definiÃ§Ã£o caracterÃ­sticas")

        elif len(concepts) > 1:
            # Buscas para cada conceito principal
            for concept in concepts[:num_searches-1]:
                queries.append(concept)

        else:
            # ExpansÃµes da query original
            expansions = [
                f"{question} explicaÃ§Ã£o detalhada",
                f"{question} Allan Kardec codificaÃ§Ã£o",
                f"{question} ensinamentos espÃ­ritas"
            ]
            queries.extend(expansions[:num_searches-1])

        # Garantir que temos exatamente num_searches queries
        return queries[:num_searches]

    def _deduplicate_and_rerank(
        self,
        sources: List,
        original_question: str,
        k: int
    ) -> List:
        """Remove duplicatas e reranqueia por relevÃ¢ncia"""

        # Remover duplicatas baseado no conteÃºdo
        seen_contents = set()
        unique_sources = []

        for source in sources:
            # Usar primeiros 200 caracteres como identificador
            content_id = source.page_content[:200].strip()

            if content_id not in seen_contents:
                seen_contents.add(content_id)
                unique_sources.append(source)

        # Reranquear por prioridade + relevÃ¢ncia
        # (priority_retriever.py jÃ¡ faz isso, mas reforÃ§ar)
        from priority_retriever import rerank_by_priority
        reranked = rerank_by_priority(unique_sources)

        # Retornar top-k
        return reranked[:k]
```

#### **Componente 2: IntegraÃ§Ã£o com API**

```python
# Modificar backend/api_server.py

# Linha ~16 (adicionar import)
from multi_search import MultiSearchEngine

# Linha ~143 (adicionar variÃ¡vel global)
multi_search_engine = None

# Linha ~253 (inicializar no startup)
@app.on_event("startup")
async def startup_event():
    global vectorstore, startup_time, multi_search_engine

    # ... cÃ³digo existente ...

    # NOVO: Inicializar multi-search engine
    print("ğŸ” Inicializando motor de mÃºltiplas buscas...")
    multi_search_engine = MultiSearchEngine(vectorstore)
    print("âœ… Motor de mÃºltiplas buscas pronto!")

# Linha ~435 (substituir busca simples por multi-search)
@app.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    # ... validaÃ§Ã£o existente ...

    # SUBSTITUIR:
    # sources = prioritized_search(...)

    # POR:
    # Multi-search adaptativo
    status_tracker.update_task(task_id, "multi_searching", 30)
    print(f"ğŸ” Iniciando multi-search adaptativo...")

    sources, search_metadata = multi_search_engine.multi_search(
        request.question,
        k=request.top_k,
        fetch_k=request.fetch_k,
        max_searches=5  # Limite mÃ¡ximo de buscas
    )

    print(f"âœ… Multi-search completo: {search_metadata['num_searches']} buscas, "
          f"{search_metadata['unique_documents']} documentos Ãºnicos")

    # Adicionar metadata Ã s fontes
    for source in sources:
        source.metadata['search_metadata'] = search_metadata

    # ... resto do cÃ³digo existente ...
```

### Fluxo de MÃºltiplas Buscas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pergunta do        â”‚
â”‚   UsuÃ¡rio            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ANÃLISE DE COMPLEXIDADE         â”‚
â”‚  - Extrair conceitos                â”‚
â”‚  - Detectar comparaÃ§Ãµes             â”‚
â”‚  - Identificar sub-perguntas        â”‚
â”‚  - Determinar nÃ­vel (1, 2 ou 3)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. DECISÃƒO DE ESTRATÃ‰GIA           â”‚
â”‚                                     â”‚
â”‚  NÃ­vel 1: 1 busca                   â”‚
â”‚  NÃ­vel 2: 2-3 buscas                â”‚
â”‚  NÃ­vel 3: 3-5 buscas                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. GERAÃ‡ÃƒO DE QUERIES              â”‚
â”‚  - Query original                   â”‚
â”‚  - Queries por conceito             â”‚
â”‚  - Queries expandidas               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. EXECUÃ‡ÃƒO DE BUSCAS              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Busca 1: Query original     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Busca 2: Conceito A         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Busca 3: Conceito B         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             ...                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. COMBINAÃ‡ÃƒO E DEDUPLICAÃ‡ÃƒO       â”‚
â”‚  - Remover documentos duplicados    â”‚
â”‚  - Reranquear por prioridade        â”‚
â”‚  - Selecionar top-K Ãºnicos          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. GERAÃ‡ÃƒO DE RESPOSTA             â”‚
â”‚  - Contexto enriquecido             â”‚
â”‚  - MÃºltiplas perspectivas           â”‚
â”‚  - Resposta mais completa           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Casos de Uso Detalhados

### Caso 1: Pergunta Simples
```
Entrada: "O que Ã© perispÃ­rito?"

AnÃ¡lise:
- Complexidade: NÃ­vel 1
- Conceitos: ["perispÃ­rito"]
- Buscas recomendadas: 1

ExecuÃ§Ã£o:
- Busca 1: "O que Ã© perispÃ­rito?"

Resultado: 3-5 documentos sobre perispÃ­rito
```

### Caso 2: Pergunta com RelaÃ§Ã£o
```
Entrada: "Qual a relaÃ§Ã£o entre perispÃ­rito e reencarnaÃ§Ã£o?"

AnÃ¡lise:
- Complexidade: NÃ­vel 2
- Conceitos: ["perispÃ­rito", "reencarnaÃ§Ã£o"]
- Ã‰ comparativa: Sim
- Buscas recomendadas: 3

ExecuÃ§Ã£o:
- Busca 1: "Qual a relaÃ§Ã£o entre perispÃ­rito e reencarnaÃ§Ã£o?"
- Busca 2: "perispÃ­rito definiÃ§Ã£o caracterÃ­sticas"
- Busca 3: "reencarnaÃ§Ã£o processo"

Resultado: 9-12 documentos cobrindo ambos conceitos e relaÃ§Ãµes
```

### Caso 3: Pergunta Complexa Multi-Conceito
```
Entrada: "Como a mediunidade, o perispÃ­rito e a evoluÃ§Ã£o espiritual
          se relacionam no processo de reencarnaÃ§Ã£o?"

AnÃ¡lise:
- Complexidade: NÃ­vel 3
- Conceitos: ["mediunidade", "perispÃ­rito", "evoluÃ§Ã£o", "reencarnaÃ§Ã£o"]
- Buscas recomendadas: 5

ExecuÃ§Ã£o:
- Busca 1: "Como a mediunidade, o perispÃ­rito e a evoluÃ§Ã£o espiritual..."
- Busca 2: "mediunidade"
- Busca 3: "perispÃ­rito"
- Busca 4: "evoluÃ§Ã£o espiritual"
- Busca 5: "reencarnaÃ§Ã£o processo"

Resultado: 15-20 documentos Ãºnicos cobrindo todos os aspectos
```

### Caso 4: Pergunta Comparativa entre Livros
```
Entrada: "Compare as visÃµes sobre caridade em O Livro dos EspÃ­ritos
          e O Evangelho Segundo o Espiritismo"

AnÃ¡lise:
- Complexidade: NÃ­vel 3
- Conceitos: ["caridade", "livro dos espÃ­ritos", "evangelho"]
- Ã‰ comparativa: Sim
- Buscas recomendadas: 4

ExecuÃ§Ã£o:
- Busca 1: "Compare as visÃµes sobre caridade..."
- Busca 2: "caridade livro dos espÃ­ritos"
- Busca 3: "caridade evangelho segundo espiritismo"
- Busca 4: "caridade definiÃ§Ã£o Allan Kardec"

Resultado: 12-15 documentos de ambas as obras sobre caridade
```

## ğŸ“Š BenefÃ­cios Esperados

### Qualidade das Respostas
1. **Maior Cobertura**: Perguntas complexas recebem informaÃ§Ãµes de mÃºltiplas fontes
2. **Mais Completas**: Respostas abordam diferentes Ã¢ngulos do tema
3. **Melhor CorrelaÃ§Ã£o**: InformaÃ§Ãµes complementares de diferentes obras
4. **Menos Lacunas**: Menor chance de perder informaÃ§Ãµes relevantes

### Performance
1. **Adaptativo**: Perguntas simples nÃ£o sofrem overhead desnecessÃ¡rio
2. **Otimizado**: DeduplicaÃ§Ã£o evita redundÃ¢ncia
3. **Balanceado**: Limite mÃ¡ximo de buscas previne lentidÃ£o excessiva

### ExperiÃªncia do UsuÃ¡rio
1. **TransparÃªncia**: UsuÃ¡rio vÃª quantas buscas foram realizadas
2. **ConfianÃ§a**: Respostas mais fundamentadas em mÃºltiplas fontes
3. **Alinhado com Promessa**: Funcionalidade "estilo Perplexity" implementada

## ğŸ¯ MÃ©tricas de Sucesso

### KPIs
1. **Melhoria na Completude**: % de respostas mais completas
   - Meta: +40% para perguntas complexas
2. **SatisfaÃ§Ã£o do UsuÃ¡rio**: Feedback positivo
   - Meta: +25% de avaliaÃ§Ãµes "Boa"
3. **LatÃªncia AceitÃ¡vel**: Tempo de resposta
   - Meta: < 10s para 3 buscas, < 15s para 5 buscas
4. **Uso Adaptativo**: % de perguntas que realmente precisam mÃºltiplas buscas
   - Esperado: 30-40% NÃ­vel 2-3, 60-70% NÃ­vel 1

### Testes de ValidaÃ§Ã£o
- [ ] 20 perguntas simples â†’ Devem usar 1 busca
- [ ] 20 perguntas mÃ©dias â†’ Devem usar 2-3 buscas
- [ ] 20 perguntas complexas â†’ Devem usar 3-5 buscas
- [ ] Comparar qualidade antes/depois (avaliaÃ§Ã£o humana)
- [ ] Medir latÃªncia mÃ©dia por nÃ­vel

## ğŸ“ DocumentaÃ§Ã£o a Atualizar

### README.md
```markdown
## ğŸ” Sistema de MÃºltiplas Buscas

O assistente realiza **mÃºltiplas buscas automÃ¡ticas** para perguntas complexas:

### NÃ­veis de Busca
- **Simples**: 1 busca para perguntas diretas
- **MÃ©dia**: 2-3 buscas para relaÃ§Ãµes entre conceitos
- **Complexa**: 3-5 buscas para perguntas multi-facetadas

### Exemplo
"Qual a relaÃ§Ã£o entre perispÃ­rito e reencarnaÃ§Ã£o?"
â†’ 3 buscas automÃ¡ticas:
  1. Query original
  2. Foco em perispÃ­rito
  3. Foco em reencarnaÃ§Ã£o
â†’ Resposta mais completa com mÃºltiplas perspectivas
```

## âš™ï¸ ConfiguraÃ§Ãµes AjustÃ¡veis

### Limites de Busca
```python
# config.py
MAX_SEARCHES = 5           # MÃ¡ximo de buscas por pergunta
MIN_SEARCHES = 1           # MÃ­nimo (sempre 1)
COMPLEXITY_THRESHOLD_L2 = 2  # Score para nÃ­vel 2
COMPLEXITY_THRESHOLD_L3 = 4  # Score para nÃ­vel 3
```

### DeduplicaÃ§Ã£o
```python
# multi_search.py
DEDUP_CONTENT_LENGTH = 200  # Caracteres para comparar duplicatas
```

## ğŸš€ Rollout Sugerido

### Fase 1: Desenvolvimento (2-3 dias)
- [ ] Criar `multi_search.py`
- [ ] Implementar `QueryAnalyzer`
- [ ] Implementar `MultiSearchEngine`
- [ ] Escrever testes unitÃ¡rios

### Fase 2: IntegraÃ§Ã£o (1-2 dias)
- [ ] Modificar `api_server.py`
- [ ] Integrar multi-search nos endpoints
- [ ] Testar com perguntas reais

### Fase 3: Testes e Ajustes (2 dias)
- [ ] Teste A/B: busca simples vs mÃºltipla
- [ ] Ajustar thresholds de complexidade
- [ ] Otimizar geraÃ§Ã£o de queries
- [ ] Validar performance

### Fase 4: Deploy (1 dia)
- [ ] DocumentaÃ§Ã£o completa
- [ ] Deploy gradual (feature flag)
- [ ] Monitoramento de latÃªncia
- [ ] Coleta de feedback

## ğŸ”„ Alternativas Consideradas

### Alternativa 1: Sempre Fazer MÃºltiplas Buscas
**PrÃ³s**: Mais simples de implementar
**Contras**: Lento para perguntas simples, desperdÃ­cio de recursos
**DecisÃ£o**: âŒ Rejeitada - nÃ£o eficiente

### Alternativa 2: LLM Decide NÃºmero de Buscas
**PrÃ³s**: DecisÃ£o "inteligente"
**Contras**: Adiciona latÃªncia, custo computacional alto
**DecisÃ£o**: âŒ Rejeitada - over-engineering

### Alternativa 3: Sistema Adaptativo Baseado em Regras (Escolhida)
**PrÃ³s**: RÃ¡pido, eficiente, previsÃ­vel, ajustÃ¡vel
**Contras**: Requer calibraÃ§Ã£o inicial
**DecisÃ£o**: âœ… Adotada

### Alternativa 4: Query Expansion com Embeddings
**PrÃ³s**: AutomÃ¡tico, baseado em similaridade
**Contras**: Menos controle, pode gerar queries ruins
**DecisÃ£o**: ğŸ¤” Considerar para v2.0

## ğŸ”® EvoluÃ§Ãµes Futuras (v2.0)

1. **Query Expansion com LLM**: Usar LLM para gerar queries melhores
2. **Aprendizado de PadrÃµes**: Aprender quais perguntas se beneficiam de mÃºltiplas buscas
3. **Busca Iterativa**: Fazer buscas adicionais baseadas em qualidade dos resultados
4. **FusÃ£o SemÃ¢ntica**: Combinar resultados de forma mais inteligente
5. **Cache de Multi-Search**: Cachear anÃ¡lises de perguntas similares

## ğŸ“š ReferÃªncias

- [Query Expansion Techniques](https://en.wikipedia.org/wiki/Query_expansion)
- [Multi-Query Retrieval in RAG](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever)
- [LangChain EnsembleRetriever](https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble)

---

**Data de CriaÃ§Ã£o**: 2025-02-01
**Autor**: Sistema de AnÃ¡lise
**RevisÃ£o**: Pendente
**Status**: ğŸ“ Proposta Inicial
